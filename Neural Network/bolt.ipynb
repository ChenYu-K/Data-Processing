{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bolt.ipynb",
      "provenance": [],
      "mount_file_id": "1xH8LGXfvKdMuG3f2Gm81C8DCP68ad0Ik",
      "authorship_tag": "ABX9TyOxs0eAO384Gp/lJkeQL4uv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChenYu-K/Data-Processing/blob/main/Neural%20Network/bolt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import os\n",
        "import cv2 as cv"
      ],
      "metadata": {
        "id": "OV_x3JfUFfxO"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_path='/content/drive/MyDrive/datebase/bolt'"
      ],
      "metadata": {
        "id": "-xURqpkzSKnC"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names=os.listdir('/content/drive/MyDrive/datebase/bolt/train')\n",
        "filenames=[]\n",
        "for name in names:\n",
        "  if os.path.splitext(name)[1] == '.png':\n",
        "    fname=os.path.splitext(name)[0]\n",
        "    filenames.append(fname)\n",
        "print(filenames)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cm1mP-VsdbuU",
        "outputId": "1dfafc1e-4031-4884-9038-b8e6995762ef"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['125', '124', '122', '123', '119', '120', '12', '121', '118', '117', '116', '115', '111', '113', '11', '114', '109', '110', '112', '108', '107', '106', '105', '103', '10', '102', '101', '104', '100', '1', '0', '164', '161', '160', '158', '162', '157', '159', '156', '163', '155', '16', '154', '152', '149', '150', '146', '151', '145', '147', '15', '144', '140', '137', '138', '139', '134', '14', '143', '141', '136', '135', '127', '128', '13', '132', '130', '129', '131', '133', '126', '22', '193', '198', '195', '194', '199', '192', '197', '196', '20', '2', '185', '190', '191', '186', '19', '187', '188', '189', '184', '183', '182', '181', '179', '176', '175', '18', '178', '180', '174', '177', '172', '170', '169', '168', '17', '165', '167', '173', '166', '56', '48', '52', '53', '50', '51', '49', '54', '5', '55', '47', '37', '42', '45', '43', '4', '40', '41', '46', '39', '38', '29', '3', '31', '32', '28', '33', '34', '30', '26', '25', '201', '24', '202', '204', '205', '203', '200', '21', '23', '94', '92', '90', '89', '86', '88', '85', '93', '9', '91', '87', '8', '84', '79', '76', '83', '77', '81', '80', '75', '74', '70', '72', '73', '7', '65', '68', '71', '66', '69', '67', '64', '63', '58', '61', '60', '6', '57', '62', '59', '97', '96', '98', '99', '95']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 读取图片并打标签\n",
        "用cv读取，经过基本的预处理（比如resize）后，转成pimg"
      ],
      "metadata": {
        "id": "X1OwI_byio4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_dataset(dir, set_label):\n",
        "    \"\"\"\n",
        "    set_label should be 'torch.tensor([1])' if two-catogory and positive sample\n",
        "    \"\"\"\n",
        "    train_data = []\n",
        "    labels = []\n",
        "    for file_name in os.listdir(dir):\n",
        "        img_dir = os.path.join(dir, file_name)\n",
        "        img = cv.imread(img_dir)\n",
        "        #img = cv.resize(img, (120, 120))            # resize img\n",
        "        #pimg = Image.fromarray(img)\n",
        "        train_data.append(img)\n",
        "        labels.append(set_label)\n",
        "    return train_data, labels"
      ],
      "metadata": {
        "id": "Z3lTmbgRcBt2"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, train_label = generate_dataset('/content/drive/MyDrive/datebase/bolt/train',filenames)\n",
        "valid_data, valid_label = generate_dataset('/content/drive/MyDrive/datebase/bolt/test',filenames)"
      ],
      "metadata": {
        "id": "LTHSDl5RclQw"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 重写dataset类"
      ],
      "metadata": {
        "id": "XKEFW63EimMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data, labels, transform=None, target_transform=None):\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        imgs = []\n",
        "        for i in range(len(labels)):\n",
        "            # print(type(data[i]))    # <class 'PIL.Image.Image'>\n",
        "            im_tensor = transform(data[i]).to(torch.device(\"cpu\"))\n",
        "            imgs.append((im_tensor, labels[i]))\n",
        "        self.imgs = imgs                         # DataLoader通过getitem读取图片数据\n",
        "    def __getitem__(self, index):\n",
        "        fn, label = self.imgs[index]\n",
        "        return fn, label\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "#原文链接：https://blog.csdn.net/csdntcl/article/details/121107971"
      ],
      "metadata": {
        "id": "z2xn-cMGicOt"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 用MyDataset构建数据集"
      ],
      "metadata": {
        "id": "vhWd7bcriixt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normMean = [0.35174567, 0.4027052, 0.39986762]\n",
        "normStd = [0.18738173, 0.17127964, 0.1971462]\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),  # range [0, 255] -> [0.0,1.0]   \n",
        "    transforms.Normalize(normMean, normStd)\n",
        "    ])\n",
        "# 也可以再定义train_transform加入一些数据增强 \n",
        "train_data = MyDataset(train_data, train_labels, transform=transform)\n",
        "valid_data = MyDataset(valid_data, valid_labels, transform=transform)\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(dataset=valid_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "————————————————\n",
        "版权声明：本文为CSDN博主「火星程猿」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。\n",
        "原文链接：https://blog.csdn.net/csdntcl/article/details/121107971"
      ],
      "metadata": {
        "id": "qoBQsIo_if4y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}