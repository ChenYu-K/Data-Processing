{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import os\n",
    "import cv2 as cv\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the data and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getlabel(dir):\n",
    "    labels=[]\n",
    "    for name in os.listdir(dir):\n",
    "        if os.path.splitext(name)[1] == '.png':\n",
    "            fname=os.path.splitext(name)[0]\n",
    "            labels.append(fname)\n",
    "    return labels\n",
    "\n",
    "def generate_dataset(dir, set_label):\n",
    "    \"\"\"\n",
    "    set_label should be 'torch.tensor([1])' if two-catogory and positive sample\n",
    "    \"\"\"\n",
    "    train_data = []\n",
    "    labels = []\n",
    "    for file_name in os.listdir(dir):\n",
    "        img_dir = os.path.join(dir, file_name)\n",
    "        img = cv.imread(img_dir)\n",
    "        #img = cv.resize(img, (120, 120))            # resize img\n",
    "        pimg = Image.fromarray(c.img)\n",
    "        train_data.append(img)\n",
    "        labels.append(set_label)\n",
    "    return train_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-39d6e095b00a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtraindir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'./test/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mvaliddir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./train/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraindir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgetlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraindir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mvalid_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvaliddir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgetlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvaliddir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-e919ffc0ee94>\u001b[0m in \u001b[0;36mgenerate_dataset\u001b[1;34m(dir, set_label)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m#img = cv.resize(img, (120, 120))            # resize img\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mpimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'c' is not defined"
     ]
    }
   ],
   "source": [
    "traindir='./test/'\n",
    "validdir = './train/'\n",
    "train_data, train_label = generate_dataset(traindir,getlabel(traindir))\n",
    "valid_data, valid_label = generate_dataset(validdir,getlabel(validdir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 重写dataset类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None, target_transform=None):\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        imgs = []\n",
    "        for i in range(len(labels)):\n",
    "            # print(type(data[i]))    # <class 'PIL.Image.Image'>\n",
    "            im_tensor = transform(data[i]).to(torch.device(\"cpu\"))\n",
    "            imgs.append((im_tensor, labels[i]))\n",
    "        self.imgs = imgs                         # DataLoader通过getitem读取图片数据\n",
    "    def __getitem__(self, index):\n",
    "        fn, label = self.imgs[index]\n",
    "        return fn, label\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用MyDataset构建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normMean = [0.35174567, 0.4027052, 0.39986762]\n",
    "normStd = [0.18738173, 0.17127964, 0.1971462]\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),  # range [0, 255] -> [0.0,1.0]   \n",
    "    transforms.Normalize(normMean, normStd)\n",
    "    ])\n",
    "# 也可以再定义train_transform加入一些数据增强 \n",
    "train_data = MyDataset(train_data, train_label, transform=transform)\n",
    "valid_data = MyDataset(valid_data, valid_label, transform=transform)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=valid_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creat BP-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as Fun\n",
    "# 定义BP神经网络\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden)\n",
    "        self.out = torch.nn.Linear(n_hidden, n_output)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = Fun.relu(self.hidden(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(n_feature=4, n_hidden=20, n_output=3)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.05)\n",
    "# SGD:随机梯度下降法\n",
    "loss_func = torch.nn.CrossEntropyLoss\n",
    "# 设定损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d275927c00a0479f68d184c1249dfe922f7fe254dc78c71a5746e4d4edecd5dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
