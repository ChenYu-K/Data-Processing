{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import os\n",
    "import cv2 as cv\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as f\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('hallo')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Define the data and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def getlabel(dir):\n",
    "    labels=[]\n",
    "    for name in os.listdir(dir):\n",
    "        if os.path.splitext(name)[1] == '.png':\n",
    "            fname=os.path.splitext(name)[0]\n",
    "            labels.append(fname)\n",
    "    labels = list(map(int, labels))\n",
    "    return torch.tensor(labels)\n",
    "\n",
    "def generate_dataset(dir):\n",
    "    \"\"\"\n",
    "    set_label should be 'torch.tensor([1])' if two-catogory and positive sample\n",
    "    \"\"\"\n",
    "    train_data = []\n",
    "    for file_name in os.listdir(dir):\n",
    "        img_dir = os.path.join(dir, file_name)\n",
    "        img = cv.imread(img_dir)\n",
    "        img = cv.resize(img, (769, 432))   # /5 resize img\n",
    "        #img_gray = cv.cvtColor(img,cv.COLOR_RGB2GRAY)\n",
    "        pimg = Image.fromarray(img)\n",
    "        train_data.append(pimg)\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "traindir= './train/'\n",
    "validdir = './test/'\n",
    "train_data0 = generate_dataset(traindir)\n",
    "train_label0=getlabel(traindir)\n",
    "valid_data0 = generate_dataset(validdir)\n",
    "valid_label0 = getlabel(validdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 重写dataset类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None, target_transform=None):\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        imgs = []\n",
    "        for i in range(len(labels)):\n",
    "            # print(type(data[i]))    # <class 'PIL.Image.Image'>\n",
    "            im_tensor = transform(data[i]).to(torch.device(\"cpu\"))\n",
    "            imgs.append((im_tensor, labels[i]))\n",
    "        self.imgs = imgs                         # DataLoader通过getitem读取图片数据\n",
    "    def __getitem__(self, index):\n",
    "        fn, label = self.imgs[index]\n",
    "        return fn, label\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 用MyDataset构建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "normMean = [0.35174567, 0.4027052, 0.39986762]\n",
    "normStd = [0.18738173, 0.17127964, 0.1971462]\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Grayscale(num_output_channels=1), #彩色图像转灰度图像num_output_channels默认1\n",
    "    transforms.ToTensor(),  # range [0, 255] -> [0.0,1.0]   \n",
    "    #transforms.Normalize(normMean, normStd)\n",
    "    ])\n",
    "# 也可以再定义train_transform加入一些数据增强 \n",
    "train_data = MyDataset(train_data0, train_label0, transform=transform)\n",
    "valid_data = MyDataset(valid_data0, valid_label0, transform=transform)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=2, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_data, batch_size=2, shuffle=True)\n",
    "dataiter=iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 定义网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    # Net类的初始化函数\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        # 继承父类的初始化函数\n",
    "        super(Net, self).__init__()\n",
    "        # 网络的隐藏层创建，名称可以随便起\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(3)\n",
    "        self.conv2 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(6)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.fc1 = nn.Linear(6*108*192, 200)\n",
    "        self.hidden_layer = torch.nn.Linear(n_feature, n_hidden)\n",
    "        # 输出层(预测层)创建，接收来自隐含层的数据\n",
    "        self.predict_layer = torch.nn.Linear(n_hidden, n_output)\n",
    "\n",
    "    # 网络的前向传播函数，构造计算图\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))      #432-3+1=430,430/2=215;769-3+1=767,767/2=384\n",
    "        x = F.relu(self.bn2(self.conv2(x)))                #215-3+1=213,213/2=108;384-3+1=382,382/2=192\n",
    "        x = self.pool(x)   \n",
    "        x = x.view(-1, 6*108*192)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # 用relu函数处理隐含层输出的结果并传给输出层\n",
    "        hidden_result = self.hidden_layer(x)\n",
    "        relu_result = F.relu(hidden_result)\n",
    "        predict_result = self.predict_layer(relu_result)\n",
    "        return predict_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 调整网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 训练次数\n",
    "TRAIN_TIMES = 300\n",
    "# 输入输出的数据维度，这里都是1维\n",
    "INPUT_FEATURE_DIM = 200\n",
    "OUTPUT_FEATURE_DIM = 1\n",
    "# 隐含层中神经元的个数\n",
    "NEURON_NUM = 200\n",
    "# 学习率，越大学的越快，但也容易造成不稳定，准确率上下波动的情况\n",
    "LEARNING_RATE = 0.1\n",
    "# unsqueeze函数可以将一维数据变成二维数据，在torch中只能处理二维数据\n",
    "#x_data = torch.unsqueeze(torch.linspace(-4, 4, 80), dim=1)\n",
    "# randn函数用于生成服从正态分布的随机数\n",
    "#y_data = x_data.pow(3) + 3 * torch.randn(x_data.size())\n",
    "#y_data_real = x_data.pow(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 建立网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=124416, out_features=200, bias=True)\n",
      "  (hidden_layer): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (predict_layer): Linear(in_features=200, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net(n_feature=INPUT_FEATURE_DIM, n_hidden=NEURON_NUM, n_output=OUTPUT_FEATURE_DIM)\n",
    "print(net)\n",
    "# 训练网络\n",
    "# 这里也可以使用其它的优化方法\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=LEARNING_RATE)\n",
    "# 定义一个误差计算方法\n",
    "loss_func = torch.nn.CrossEntropyLoss() # 定义交叉熵损失函数 交叉熵损失函数是用来衡量两个概率分布之间的距离的#nn.MSELoss()\n",
    "# Define the loss function with Classification Cross-Entropy loss and an optimizer with Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Target 145 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32mf:\\database\\bolt\\bolt_RNN.ipynb Cell 16\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      <a href='vscode-notebook-cell:/f%3A/database/bolt/bolt_RNN.ipynb#ch0000015?line=2'>3</a>\u001B[0m prediction \u001B[39m=\u001B[39m net(images)\n\u001B[0;32m      <a href='vscode-notebook-cell:/f%3A/database/bolt/bolt_RNN.ipynb#ch0000015?line=3'>4</a>\u001B[0m \u001B[39m# 计算预测值与真值误差，注意参数顺序问题\u001B[39;00m\n\u001B[0;32m      <a href='vscode-notebook-cell:/f%3A/database/bolt/bolt_RNN.ipynb#ch0000015?line=4'>5</a>\u001B[0m \u001B[39m# 第一个参数为预测值，第二个为真值\u001B[39;00m\n\u001B[1;32m----> <a href='vscode-notebook-cell:/f%3A/database/bolt/bolt_RNN.ipynb#ch0000015?line=5'>6</a>\u001B[0m loss \u001B[39m=\u001B[39m loss_func(prediction, labels)\n\u001B[0;32m      <a href='vscode-notebook-cell:/f%3A/database/bolt/bolt_RNN.ipynb#ch0000015?line=7'>8</a>\u001B[0m \u001B[39m# 开始优化步骤\u001B[39;00m\n\u001B[0;32m      <a href='vscode-notebook-cell:/f%3A/database/bolt/bolt_RNN.ipynb#ch0000015?line=8'>9</a>\u001B[0m \u001B[39m# 每次开始优化前将梯度置为0\u001B[39;00m\n\u001B[0;32m     <a href='vscode-notebook-cell:/f%3A/database/bolt/bolt_RNN.ipynb#ch0000015?line=9'>10</a>\u001B[0m optimizer\u001B[39m.\u001B[39mzero_grad()\n",
      "File \u001B[1;32mc:\\Users\\brcy\\anaconda3\\envs\\pytorch-cy1\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[39m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m (\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_backward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_pre_hooks \u001B[39mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[39mor\u001B[39;00m _global_forward_hooks \u001B[39mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[39mreturn\u001B[39;00m forward_call(\u001B[39m*\u001B[39m\u001B[39minput\u001B[39m, \u001B[39m*\u001B[39m\u001B[39m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[39m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[39m=\u001B[39m [], []\n",
      "File \u001B[1;32mc:\\Users\\brcy\\anaconda3\\envs\\pytorch-cy1\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1164\u001B[0m, in \u001B[0;36mCrossEntropyLoss.forward\u001B[1;34m(self, input, target)\u001B[0m\n\u001B[0;32m   1163\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39mforward\u001B[39m(\u001B[39mself\u001B[39m, \u001B[39minput\u001B[39m: Tensor, target: Tensor) \u001B[39m-\u001B[39m\u001B[39m>\u001B[39m Tensor:\n\u001B[1;32m-> 1164\u001B[0m     \u001B[39mreturn\u001B[39;00m F\u001B[39m.\u001B[39;49mcross_entropy(\u001B[39minput\u001B[39;49m, target, weight\u001B[39m=\u001B[39;49m\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mweight,\n\u001B[0;32m   1165\u001B[0m                            ignore_index\u001B[39m=\u001B[39;49m\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mignore_index, reduction\u001B[39m=\u001B[39;49m\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mreduction,\n\u001B[0;32m   1166\u001B[0m                            label_smoothing\u001B[39m=\u001B[39;49m\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mlabel_smoothing)\n",
      "File \u001B[1;32mc:\\Users\\brcy\\anaconda3\\envs\\pytorch-cy1\\lib\\site-packages\\torch\\nn\\functional.py:3014\u001B[0m, in \u001B[0;36mcross_entropy\u001B[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001B[0m\n\u001B[0;32m   3012\u001B[0m \u001B[39mif\u001B[39;00m size_average \u001B[39mis\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39mNone\u001B[39;00m \u001B[39mor\u001B[39;00m reduce \u001B[39mis\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39mNone\u001B[39;00m:\n\u001B[0;32m   3013\u001B[0m     reduction \u001B[39m=\u001B[39m _Reduction\u001B[39m.\u001B[39mlegacy_get_string(size_average, reduce)\n\u001B[1;32m-> 3014\u001B[0m \u001B[39mreturn\u001B[39;00m torch\u001B[39m.\u001B[39;49m_C\u001B[39m.\u001B[39;49m_nn\u001B[39m.\u001B[39;49mcross_entropy_loss(\u001B[39minput\u001B[39;49m, target, weight, _Reduction\u001B[39m.\u001B[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001B[1;31mIndexError\u001B[0m: Target 145 is out of bounds."
     ]
    }
   ],
   "source": [
    "for i in range(TRAIN_TIMES):\n",
    "    # 输入数据进行预测\n",
    "    prediction = net(images)\n",
    "    # 计算预测值与真值误差，注意参数顺序问题\n",
    "    # 第一个参数为预测值，第二个为真值\n",
    "    loss = loss_func(prediction, labels)\n",
    "\n",
    "    # 开始优化步骤\n",
    "    # 每次开始优化前将梯度置为0\n",
    "    optimizer.zero_grad()\n",
    "    # 误差反向传播\n",
    "    loss.backward()\n",
    "    # 按照最小loss优化参数\n",
    "    optimizer.step()\n",
    "\n",
    "    # 可视化训练结果\n",
    "    if i % 2 == 0:\n",
    "        # 清空上一次显示结果\n",
    "        plt.cla()\n",
    "        # 无误差真值曲线\n",
    "        plt.plot(x_data.numpy(), y_data_real.numpy(), c='blue', lw='3')\n",
    "        # 有误差散点\n",
    "        plt.scatter(x_data.numpy(), y_data.numpy(), c='orange')\n",
    "        # 实时预测的曲线\n",
    "        plt.plot(x_data.numpy(), prediction.data.numpy(), c='red', lw='2')\n",
    "        plt.text(-0.5, -65, 'Time=%d Loss=%.4f' % (i, loss.data.numpy()), fontdict={'size': 15, 'color': 'red'})\n",
    "        plt.pause(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "0ec9779f063a942372247cf944fedbbc91251caa904973c75af8af67dbd8132d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}